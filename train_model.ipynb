{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    computing_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get paths to files\n",
    "\n",
    "# train_files = ['data/MT8_8K.wav']\n",
    "# train_files = ['data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "# val_files = ['data/01_8K.wav']\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "in_files = []\n",
    "for root, dirs, files in os.walk(\"data/shijin\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            in_files += [root + '/' + file]\n",
    "np.random.shuffle(in_files)\n",
    "train_files = in_files[:int(train_ratio*len(in_files))]\n",
    "val_files = in_files[int(train_ratio*len(in_files)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: data/shijin/09.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1070)\n",
      "Data processing complete, X shape: torch.Size([180, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/10.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1507)\n",
      "Data processing complete, X shape: torch.Size([260, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/11.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1618)\n",
      "Data processing complete, X shape: torch.Size([280, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/14.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1550)\n",
      "Data processing complete, X shape: torch.Size([260, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/02.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1565)\n",
      "Data processing complete, X shape: torch.Size([280, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/01.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1332)\n",
      "Data processing complete, X shape: torch.Size([240, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/03.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1261)\n",
      "Data processing complete, X shape: torch.Size([220, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/08.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1896)\n",
      "Data processing complete, X shape: torch.Size([320, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/07.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 892)\n",
      "Data processing complete, X shape: torch.Size([160, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/06.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1044)\n",
      "Data processing complete, X shape: torch.Size([180, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/13.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1302)\n",
      "Data processing complete, X shape: torch.Size([220, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/05.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1046)\n",
      "Data processing complete, X shape: torch.Size([180, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/04.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 1859)\n",
      "Data processing complete, X shape: torch.Size([320, 6, 2048])\n",
      "\n",
      "Loading file: data/shijin/12.wav, sample rate: 8000\n",
      "Completed STFT, data shape: (1024, 988)\n",
      "Data processing complete, X shape: torch.Size([180, 6, 2048])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataloader init\n",
    "\n",
    "from util import *\n",
    "\n",
    "chunk_size = 20\n",
    "window_size = 2046\n",
    "window_overlap = 1023\n",
    "batch_size = 6\n",
    "\n",
    "train_gen = DataGenerator(train_files, chunk_size, window_size, window_overlap, batch_size)\n",
    "val_gen = DataGenerator(val_files, chunk_size, window_size, window_overlap, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "\n",
    "from lstm import *\n",
    "\n",
    "input_dim = train_gen.X_list[0].shape[2] #TODO\n",
    "hidden_dim = 2048\n",
    "num_layers = 1\n",
    "\n",
    "# model = LSTMBasic(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size)\n",
    "# model = LSTMFC(input_dim, hidden_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size, dropout_p=0.2)\n",
    "model = LSTMCNN(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size, decoder=\"2fc\")\n",
    "\n",
    "model = model.to(computing_device)\n",
    "criterion = nn.MSELoss().to(computing_device)\n",
    "dp = nn.DataParallel(model, dim=1).to(computing_device)\n",
    "m = dp.module\n",
    "optimizer = torch.optim.Adam(dp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# trainer setup\n",
    "\n",
    "from lstm_trainer import *\n",
    "trainer = LSTMTrainer(dp, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model? \n",
    "\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    epochs_trained = 1000\n",
    "#     model_file = \"models/cs{}_h{}_e{}.ckpt\".format(chunk_size, hidden_dim, epochs_trained)\n",
    "    model_file = \"models/cs20_h2048_e4000.ckpt\"\n",
    "    print(\"Loading model: {}\".format(model_file))\n",
    "    trainer.load_model(model_file, epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 0278 | 02.wav               | Chunk 014 [############################--]092.9% | T+1:20:12.690396\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 0375 | 11.wav               | Chunk 007 [#############-----------------]042.9% | T+1:47:47.891699\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 0466 | 11.wav               | Chunk 007 [#############-----------------]042.9% | T+2:13:57.903380\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3500 | 03.wav               | Chunk 004 [#########---------------------]027.3% | T+2:23:12.111464\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3596 | 01.wav               | Chunk 002 [###---------------------------]008.3% | T+2:50:57.316586\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4040 | 11.wav               | Chunk 004 [#######-----------------------]021.4% | T+0:11:24.066233\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cse253/fp/lstm_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_gen, val_gen, n_epochs, shuffle, dump_model, dump_epochs, dump_loss)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                     \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training\n",
    "\n",
    "train_model = True\n",
    "iter_epochs = 1000\n",
    "iters = 5\n",
    "dump_epochs = 500\n",
    "\n",
    "if train_model:\n",
    "    \n",
    "#     fig = plt.figure(figsize=(6,3))\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     fig.show(); fig.canvas.draw()\n",
    "    \n",
    "    # train a series of models at different numbers of epochs\n",
    "    curr_train_losses, curr_val_losses = [], []\n",
    "    for i in range(iters):\n",
    "\n",
    "        train_loss, val_loss = trainer.train(train_gen, val_gen, iter_epochs, 1,\n",
    "                                             dump_model=True, dump_epochs=dump_epochs, dump_loss=True)\n",
    "        curr_train_losses += train_loss  # train_loss is a 2D python list/\n",
    "        curr_val_losses += val_loss\n",
    "        \n",
    "        # plot loss curve\n",
    "#         ax.clear()\n",
    "#         ax.plot(np.array(curr_train_losses).mean(axis=1))\n",
    "#         fig.canvas.draw()\n",
    "        \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# train_loss = []\n",
    "# val_loss = []\n",
    "# for i in range(80):\n",
    "#     t,v = pickle.load(open(\"models/model_h150_e{}.ckpt.loss.pkl\".format((i+1)*10), 'rb'))\n",
    "#     train_loss += [t]\n",
    "#     val_loss += [v]\n",
    "# plt.plot(np.average(np.array(train_loss).reshape((800,3799)), axis=1))\n",
    "# plt.plot(np.average(np.array(val_loss).reshape((800,674)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc. tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "STOP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f8540e0e5451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STOP\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dirty way to stop the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: STOP"
     ]
    }
   ],
   "source": [
    "raise Exception(\"STOP\") # dirty way to stop the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20\n",
    "window_size = 2046\n",
    "window_overlap = 1023\n",
    "batch_size = 2\n",
    "\n",
    "# test_files = ['data/05_8K.wav']#, 'data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "test_files = in_files[-1:]\n",
    "\n",
    "test_gen = DataGenerator(test_files, chunk_size, window_size, window_overlap, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, X, T = test_gen[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output, hidden_states, cell_states = trainer.eval_model(test_gen, prime_len=100, gen_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo = torch.FloatTensor(eval_output)[:, 0]\n",
    "eo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,x = test_gen.reassemble_istft(eo[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs = 8000\n",
    "\n",
    "plt.specgram(x, Fs=fs, NFFT=window_size, noverlap=window_overlap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"2.wav\", fs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_states = np.array(cell_states)[:, 0, 0]\n",
    "hidden_states = np.array(hidden_states)[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(eo[:,0].transpose(0,1), cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(cell_states.transpose(), cmap='gray')\n",
    "plt.show()\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

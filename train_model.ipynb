{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    computing_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get paths to files\n",
    "\n",
    "# train_files = ['data/MT8_8K.wav']\n",
    "# train_files = ['data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "# val_files = ['data/01_8K.wav']\n",
    "\n",
    "# train_ratio = 1.0\n",
    "\n",
    "# in_files = []\n",
    "# for root, dirs, files in os.walk(\"data\"):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".wav\"):\n",
    "#             in_files += [root + '/' + file]\n",
    "# np.random.shuffle(in_files)\n",
    "# train_files = in_files[:int(train_ratio*len(in_files))]\n",
    "# val_files = in_files[int(train_ratio*len(in_files)):]\n",
    "# print(in_files[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/imgne/maestro-v1.0.0/2017/MIDI-Unprocessed_066_PIANO066_MID--AUDIO-split_07-07-17_Piano-e_3-02_wav--3.wav\n"
     ]
    }
   ],
   "source": [
    "# import maestro\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "maestro_root = \"/imgne/maestro-v1.0.0/\"\n",
    "\n",
    "meta_df_orig = pd.read_csv(maestro_root + \"maestro-v1.0.0.csv\")\n",
    "meta_df_orig[\"audio_filename\"] = meta_df_orig[\"audio_filename\"].apply(lambda x: maestro_root + x)\n",
    "meta_df = meta_df_orig[meta_df_orig[\"year\"] == 2017]\n",
    "\n",
    "shuffle(meta_df)\n",
    "\n",
    "train_files = meta_df[meta_df[\"split\"] == \"train\"][\"audio_filename\"].values\n",
    "val_files = meta_df[meta_df[\"split\"] == \"validation\"][\"audio_filename\"].values\n",
    "test_files = meta_df[meta_df[\"split\"] == \"test\"][\"audio_filename\"].values\n",
    "\n",
    "print(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataloader init\n",
    "\n",
    "from util import *\n",
    "\n",
    "chunk_size = 20\n",
    "window_size = 2046\n",
    "window_overlap = 1023\n",
    "batch_size = 8\n",
    "\n",
    "train_val_data_file = \"data/maestro2017_train_val.pkl\"\n",
    "# test_files = ['data/05_8K.wav']#, 'data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "# test_files = in_files\n",
    "\n",
    "if os.path.exists(train_val_data_file): \n",
    "    train_gen, val_gen = pickle.load(open(train_val_data_file, 'rb'))\n",
    "else:\n",
    "    train_gen = DataGenerator(train_files, chunk_size, window_size, window_overlap, batch_size)\n",
    "    val_gen = DataGenerator(val_files, chunk_size, window_size, window_overlap, batch_size)\n",
    "    pickle.dump((train_gen, val_gen), open(train_val_data_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "\n",
    "from lstm import *\n",
    "\n",
    "input_dim = train_gen.X_list[0].shape[2] #TODO\n",
    "hidden_dim = 2048\n",
    "num_layers = 1\n",
    "\n",
    "# model = LSTMBasic(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size)\n",
    "# model = LSTMFC(input_dim, hidden_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size, dropout_p=0.2)\n",
    "model = LSTMCNN(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size, decoder=\"2fc\", normalize=True)\n",
    "\n",
    "model = model.to(computing_device)\n",
    "criterion = nn.MSELoss().to(computing_device)\n",
    "dp = nn.DataParallel(model, dim=1, device_ids=[0,1,2,3]).to(computing_device)\n",
    "m = dp.module\n",
    "optimizer = torch.optim.Adam(dp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# trainer setup\n",
    "\n",
    "from lstm_trainer import *\n",
    "trainer = LSTMTrainer(dp, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model? \n",
    "\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    epochs_trained = 480\n",
    "    model_file = \"models/cs{}_h{}_e{}.ckpt\".format(chunk_size, hidden_dim, epochs_trained)\n",
    "#     model_file = \"models/cs20_h2048_e{}.ckpt\"\n",
    "    print(\"Loading model: {}\".format(model_file))\n",
    "    trainer.load_model(model_file, epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 0002 | MIDI-Unprocessed_051 | Chunk 025 [#######################-------]075.0% | T+0:06:46.364025\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training\n",
    "\n",
    "train_model = True\n",
    "iter_epochs = 100\n",
    "iters = 50\n",
    "dump_epochs = 10\n",
    "\n",
    "if train_model:\n",
    "    \n",
    "#     fig = plt.figure(figsize=(6,3))\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     fig.show(); fig.canvas.draw()\n",
    "    \n",
    "    # train a series of models at different numbers of epochs\n",
    "    curr_train_losses, curr_val_losses = [], []\n",
    "    for i in range(iters):\n",
    "\n",
    "        train_loss, val_loss = trainer.train(train_gen, val_gen, iter_epochs, 1,\n",
    "                                             dump_model=False, dump_epochs=dump_epochs, dump_loss=False)\n",
    "        curr_train_losses += train_loss  # train_loss is a 2D python list/\n",
    "        curr_val_losses += val_loss\n",
    "        \n",
    "        # plot loss curve\n",
    "#         ax.clear()\n",
    "#         ax.plot(np.array(curr_train_losses).mean(axis=1))\n",
    "#         fig.canvas.draw()\n",
    "        \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# train_loss = []\n",
    "# val_loss = []\n",
    "# for i in range(80):\n",
    "#     t,v = pickle.load(open(\"models/model_h150_e{}.ckpt.loss.pkl\".format((i+1)*10), 'rb'))\n",
    "#     train_loss += [t]\n",
    "#     val_loss += [v]\n",
    "# plt.plot(np.average(np.array(train_loss).reshape((800,3799)), axis=1))\n",
    "# plt.plot(np.average(np.array(val_loss).reshape((800,674)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc. tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"STOP\") # dirty way to stop the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20\n",
    "window_size = 2046\n",
    "window_overlap = 1023\n",
    "batch_size = 2\n",
    "\n",
    "# test_files = ['data/05_8K.wav']#, 'data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "# test_files = in_files[-1:]\n",
    "\n",
    "test_gen = DataGenerator(test_files, chunk_size, window_size, window_overlap, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, X, T = test_gen[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output, hidden_states, cell_states = trainer.eval_model(test_gen, prime_len=100, gen_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo = torch.FloatTensor(eval_output)[:, 0]\n",
    "eo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,x = test_gen.reassemble_istft(eo[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs = 8000\n",
    "\n",
    "plt.specgram(x, Fs=fs, NFFT=window_size, noverlap=window_overlap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"2.wav\", fs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_states = np.array(cell_states)[:, 0, 0]\n",
    "hidden_states = np.array(hidden_states)[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(eo[:,0].transpose(0,1), cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(cell_states.transpose(), cmap='gray')\n",
    "plt.show()\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

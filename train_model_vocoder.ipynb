{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    computing_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reader = wave.open('feather.wav', 'rb')\n",
    "print(reader.getframerate(), reader.getsampwidth(), reader.getnframes())\n",
    "nframes = reader.getnframes()\n",
    "d = np.empty(nframes)\n",
    "d = np.frombuffer(reader.readframes(nframes), dtype=np.float32, count=nframes)\n",
    "\n",
    "fs, data = wavfile.read('feather.wav')\n",
    "print(data.shape, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: feather.wav:, sample rate: 8000\n",
      "2723 1025\n",
      "[-9.59624836e-07+3.52560445e-22j  1.41015379e-06-1.32029579e-07j\n",
      " -1.89701140e-06+2.81862361e-06j ... -3.01684155e-08+4.96024923e-08j\n",
      "  3.62350463e-08-4.59308622e-08j -4.36013314e-08-1.16667567e-20j]\n",
      "Writing to feather_stft.npy; Shape: (1025, 2723)\n",
      "2723 2048\n",
      "[ 0.          0.          0.         ... -0.56136741  0.09828989\n",
      "  0.99515783]\n",
      "Writing to biiig_test.npy; Shape: (2048, 2723)\n",
      "Completed STFT, data shape: (2048, 2723)\n",
      "Data processing complete, X shape: torch.Size([2740, 1, 2048])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataloader inits\n",
    "from util import *\n",
    "\n",
    "chunk_size = 20\n",
    "window_size = 2048\n",
    "window_overlap = 1023\n",
    "batch_size = 1\n",
    "\n",
    "train_files = ['feather.wav'] \n",
    "# train_files = ['data/05_8K.wav']#, 'data/02.wav', 'data/03.wav']#, 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "val_files = ['data/01_8K.wav']\n",
    "\n",
    "train_gen = DataGenerator(train_files, chunk_size, window_size, \n",
    "                          window_overlap, batch_size, vocoder=True)\n",
    "val_gen = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "# model setup\n",
    "\n",
    "from lstm import *\n",
    "\n",
    "input_dim = train_gen.X_list[0].shape[2] #TODO\n",
    "hidden_dim = 2048\n",
    "num_layers = 1\n",
    "print(input_dim)\n",
    "\n",
    "model = LSTMBasic(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size)\n",
    "# model = LSTMFC(input_dim, hidden_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size, dropout_p=0.2)\n",
    "# model = LSTMCNN(input_dim, hidden_dim, num_layers=num_layers, batch_size=batch_size)\n",
    "\n",
    "model = model.to(computing_device)\n",
    "criterion = nn.MSELoss().to(computing_device)\n",
    "dp = nn.DataParallel(model, dim=1).to(computing_device)\n",
    "m = dp.module\n",
    "optimizer = torch.optim.Adam(dp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# trainer setup\n",
    "\n",
    "from lstm_trainer import *\n",
    "trainer = LSTMTrainer(dp, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model? \n",
    "\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    epochs_trained = 1000\n",
    "#     model_file = \"models/cs{}_h{}_e{}.ckpt\".format(chunk_size, hidden_dim, epochs_trained)\n",
    "    model_file = \"models/cs20_h2048_e4000.ckpt\"\n",
    "    print(\"Loading model: {}\".format(model_file))\n",
    "    trainer.load_model(model_file, epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0100 | feather.wav | Chunk 137 [##############################]099.3% cLoss:1.05541E-10\n",
      "CPU times: user 3min 51s, sys: 1min 33s, total: 5min 24s\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training\n",
    "\n",
    "train_model = True\n",
    "iter_epochs = 100\n",
    "iters = 1\n",
    "dump_epochs = 100\n",
    "\n",
    "if train_model:\n",
    "    \n",
    "#     fig = plt.figure(figsize=(6,3))\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     fig.show(); fig.canvas.draw()\n",
    "    \n",
    "    # train a series of models at different numbers of epochs\n",
    "    curr_train_losses, curr_val_losses = [], []\n",
    "    for i in range(iters):\n",
    "\n",
    "        train_loss, val_loss = trainer.train(train_gen, val_gen, iter_epochs, 1,\n",
    "                                             dump_model=True, dump_epochs=dump_epochs, dump_loss=False)\n",
    "        curr_train_losses += train_loss  # train_loss is a 2D python list\n",
    "        curr_val_losses += val_loss\n",
    "        \n",
    "        # plot loss curve\n",
    "#         ax.clear()\n",
    "#         ax.plot(np.array(curr_train_losses).mean(axis=1))\n",
    "#         fig.canvas.draw()\n",
    "        \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# train_loss = []\n",
    "# val_loss = []\n",
    "# for i in range(80):\n",
    "#     t,v = pickle.load(open(\"models/model_h150_e{}.ckpt.loss.pkl\".format((i+1)*10), 'rb'))\n",
    "#     train_loss += [t]\n",
    "#     val_loss += [v]\n",
    "# plt.plot(np.average(np.array(train_loss).reshape((800,3799)), axis=1))\n",
    "# plt.plot(np.average(np.array(val_loss).reshape((800,674)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc. tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "STOP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f8540e0e5451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STOP\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dirty way to stop the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: STOP"
     ]
    }
   ],
   "source": [
    "raise Exception(\"STOP\") # dirty way to stop the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: feather.wav:, sample rate: 8000\n",
      "2723 1025\n",
      "[-9.59624836e-07+3.52560445e-22j  1.41015379e-06-1.32029579e-07j\n",
      " -1.89701140e-06+2.81862361e-06j ... -3.01684155e-08+4.96024923e-08j\n",
      "  3.62350463e-08-4.59308622e-08j -4.36013314e-08-1.16667567e-20j]\n",
      "Writing to feather_stft.npy; Shape: (1025, 2723)\n",
      "2723 2048\n",
      "[0.000e+000 0.000e+000 0.000e+000 ... 5.015e-321 5.015e-321 5.015e-321]\n",
      "Writing to biiig_test.npy; Shape: (2048, 2723)\n",
      "Completed STFT, data shape: (2048, 2723)\n",
      "Data processing complete, X shape: torch.Size([2740, 1, 2048])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 20\n",
    "window_size = 2048\n",
    "#window_overlap = 1023\n",
    "batch_size = 1\n",
    "\n",
    "train_files = ['feather.wav'] \n",
    "#, 'data/02_8K.wav', 'data/03_8K.wav', 'data/04_8K.wav', 'data/05_8K.wav']\n",
    "\n",
    "test_gen = DataGenerator(train_files, chunk_size, window_size, window_overlap, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2740, 1, 2048])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname, X, T = test_gen[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200\r"
     ]
    }
   ],
   "source": [
    "m.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    m.curr_state = m.init_hidden()\n",
    "\n",
    "    eval_output = []\n",
    "    cell_states = []\n",
    "    hidden_states = []\n",
    "    \n",
    "    # prime the model with 30 seconds of input\n",
    "    primer = X[:600].to(computing_device)\n",
    "    for i in range(600):\n",
    "        out, states = m(primer[i:i+1], m.curr_state)\n",
    "        eval_output += [out.cpu().numpy()]\n",
    "        cell_states += [states[0].cpu().numpy()]\n",
    "        hidden_states += [states[1].cpu().numpy()]\n",
    "\n",
    "    # start generation \n",
    "    for i in range(200):\n",
    "        print(\"{}/{}\".format(i+1, 200), end='\\r')\n",
    "        out, states = m(out, m.curr_state)\n",
    "        eval_output += [out.cpu().numpy()]\n",
    "        cell_states += [states[0].cpu().numpy()]\n",
    "        hidden_states += [states[1].cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 1, 2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo = torch.FloatTensor(eval_output)[:, 0]\n",
    "eo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-23.4778) tensor(24.3468)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Window, STFT shape and noverlap do not satisfy the COLA constraint.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-abb0df5ff413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(chunks.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreassemble_istft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/datasets/home/home-02/67/267/duys/cse253/fp/util.py\u001b[0m in \u001b[0;36mreassemble_istft\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# do iSTFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         t, x = istft(out, fs=self.fs, #window='blackmanharris',\n\u001b[0;32m--> 172\u001b[0;31m                      nperseg=self.window_size, noverlap=self.window_overlap)\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# TODO: normalize output?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36mistft\u001b[0;34m(Zxx, fs, window, nperseg, noverlap, nfft, input_onesided, boundary, time_axis, freq_axis)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_COLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         raise ValueError('Window, STFT shape and noverlap do not satisfy the '\n\u001b[0m\u001b[1;32m   1201\u001b[0m                          'COLA constraint.')\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Window, STFT shape and noverlap do not satisfy the COLA constraint."
     ]
    }
   ],
   "source": [
    "#fname, X, T = train_gen[0]\n",
    "#print(X.shape)\n",
    "#print(X[0:chunk_size].shape)\n",
    "#chunks = torch.tensor(e[i*chunk_size*10:(i+1)*chunk_size*10])\n",
    "#print(chunks.shape)\n",
    "print(eo.min(), eo.max())\n",
    "t,x = train_gen.reassemble_istft(eo[400:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs = 8000\n",
    "\n",
    "plt.specgram(x[:1000], Fs=fs, NFFT=1024, noverlap=window_overlap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load('biiig_test.npy')\n",
    "#t = np.load('feather_stft.npy')\n",
    "\n",
    "print(t.shape)\n",
    "frames = np.fft.irfft(t).real\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavy = []\n",
    "for x in frames:\n",
    "    # apply hanning window to frame\n",
    "    print(x.shape)\n",
    "    time = np.arange(window_size)\n",
    "    hanning = 0.5 * (1 - np.cos(2 * np.pi * time / window_size))\n",
    "    x *= hanning\n",
    "    \n",
    "    \n",
    "    #np.clip(buffer, -1, 1, out=buffer)\n",
    "\n",
    "    #n = buffer.shape[1]\n",
    "    #frames = (buffer.T.reshape((-1,)) * 32676).astype(np.int16).tobytes()\n",
    "    #self._writer.writeframes(frames) lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"test2.wav\", fs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_states = np.array(cell_states)[:, 0, 0]\n",
    "hidden_states = np.array(hidden_states)[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(eo[:,0].transpose(0,1), cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(cell_states.transpose(), cmap='gray')\n",
    "plt.show()\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
